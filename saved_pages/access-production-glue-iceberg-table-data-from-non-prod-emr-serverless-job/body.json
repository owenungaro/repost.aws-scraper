{
  "body": "Hi,\ni have a use case where, i want to access/read my prod glue table data from emr serverless application job\nso i am running one job on  non prod emr serverless application studio, which needs to access prod glue iceberg table.\ni am able to read normal table from prod , but not able read iceberg table.\nnt sure about the what configuration do i need to give in my code or studio application configuration\ncurrently i have this as application configuration:\n{\n\"runtimeConfiguration\": [\n{\n\"classification\": \"spark-defaults\",\n\"configurations\": null,\n\"properties\": {\n\"spark.sql.catalog.hubble_iceberg_catalog.warehouse\": \"s3://sat-tech-platform-prod/data-dir/data/processed/databases\",\n\"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n\"spark.sql.catalogImplementation\": \"hive\",\n\"spark.sql.catalog.hubble_iceberg_catalog.glue.catalog-id\": \"Production_ACCOUNT_ID\",\n\"spark.sql.catalog.hubble_iceberg_catalog\": \"org.apache.iceberg.spark.SparkCatalog\",\n\"spark.sql.catalog.hubble_iceberg_catalog.catalog-impl\": \"org.apache.iceberg.aws.glue.GlueCatalog\",\n\"spark.sql.catalog.hubble_iceberg_catalog.io-impl\": \"org.apache.iceberg.aws.s3.S3FileIO\",\n\"spark.hadoop.hive.metastore.glue.catalogid\": \"Production_ACCOUNT_ID\"\n}\n}\n]\n}\n\nTo access Iceberg tables from a production AWS Glue Data Catalog using an EMR Serverless application in a non-production environment, you need to properly configure cross-account access. Based on your current configuration, there are a few adjustments needed.\nFor your EMR Serverless application to access Iceberg tables in a production account, you need to ensure:\nThe execution role for your EMR Serverless job has the necessary cross-account permissions to:\nAccess the production AWS Glue Data Catalog\nRead data from the production S3 bucket\nYour Spark configuration needs some adjustments:\n{\n\"runtimeConfiguration\": [\n{\n\"classification\": \"spark-defaults\",\n\"properties\": {\n\"spark.sql.catalog.hubble_iceberg_catalog\": \"org.apache.iceberg.spark.SparkCatalog\",\n\"spark.sql.catalog.hubble_iceberg_catalog.type\": \"glue\",\n\"spark.sql.catalog.hubble_iceberg_catalog.glue.id\": \"Production_ACCOUNT_ID\",\n\"spark.sql.catalog.hubble_iceberg_catalog.warehouse\": \"s3://sat-tech-platform-prod/data-dir/data/processed/databases\",\n\"spark.sql.catalog.hubble_iceberg_catalog.catalog-impl\": \"org.apache.iceberg.aws.glue.GlueCatalog\",\n\"spark.sql.catalog.hubble_iceberg_catalog.io-impl\": \"org.apache.iceberg.aws.s3.S3FileIO\",\n\"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n\"spark.sql.defaultCatalog\": \"hubble_iceberg_catalog\"\n}\n}\n]\n}\nThe key changes are:\nAdding\n\"spark.sql.catalog.hubble_iceberg_catalog.type\": \"glue\"\nto specify the catalog type\nAdding\n\"spark.sql.defaultCatalog\": \"hubble_iceberg_catalog\"\nto set this as the default catalog\nEnsuring the region is correctly set if your production account is in a different region\nWhen querying the tables, you would use:\nSELECT * FROM hubble_iceberg_catalog.database_name.table_name\nIf you're still encountering issues, check that:\nThe execution role has the necessary IAM permissions including\nlakeformation:GetDataAccess\nif Lake Formation is used\nCross-account access policies are properly set up in both accounts\nThe S3 bucket policy allows access from your non-production account\nSources\nWorking with AWS Glue multi-catalog hierarchy on EMR Serverless - Amazon EMR\nUsing Apache Iceberg with EMR Serverless - Amazon EMR\nWorking with a multi-catalog hierarchy in AWS Glue Data Catalog with Spark on Amazon EMR - Amazon EMR"
}