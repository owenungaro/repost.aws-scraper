{
  "body": "I am configuring a connection with snowflake in AWS Appflow. But I consistently get a error\nError while communicating to connector: The test connection request failed due to connector timed out.\n. I have configured the S3 , AWS role, snowflake stage, schema, snowflake storage integration , user and password.  I am using the network iD of my snowflake account e.g., My S3 has the following permission.\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Sid\": \"AllowAppFlowDestinationActions\",\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"Service\": \"appflow.amazonaws.com\"\n},\n\"Action\": [\n\"s3:PutObjectAcl\",\n\"s3:PutObject\",\n\"s3:ListMultipartUploadParts\",\n\"s3:ListBucketMultipartUploads\",\n\"s3:GetBucketAcl\",\n\"s3:AbortMultipartUpload\"\n],\n\"Resource\": [\n\"arn:aws:s3:::engagement-uat-sfmc-snowflake-dpp/*\",\n\"arn:aws:s3:::engagement-uat-sfmc-snowflake-dpp\"\n]\n}\n]\n}\nAnd IAM role that I am using for the integration has the policy\n{\n\"Statement\": [\n{\n\"Action\": [\n\"s3:PutObject\",\n\"s3:AbortMultipartUpload\",\n\"s3:ListMultipartUploadParts\",\n\"s3:ListBucketMultipartUploads\",\n\"s3:GetBucketAcl\",\n\"s3:GetObject\",\n\"s3:GetObjectVersion\",\n\"s3:DeleteObject\",\n\"s3:DeleteObjectVersion\",\n\"s3:PutObjectAcl\",\n\"s3:ListBucket\"\n],\n\"Effect\": \"Allow\",\n\"Resource\": [\n\"arn:aws:s3:::engagement-uat-sfmc-snowflake-dpp/*\",\n\"arn:aws:s3:::engagement-uat-sfmc-snowflake-dpp\"\n]\n}\n],\n\"Version\": \"2012-10-17\"\n}\nand trust relationship\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Sid\": \"ExternalAccess\",\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"AWS\": \"arn:aws:iam::672255977428:user/kpt80000-s\"\n},\n\"Action\": \"sts:AssumeRole\",\n\"Condition\": {\n\"StringLike\": {\n\"sts:ExternalId\": \"UG11430_SFCRole=2_kvQW4yCPyCk6lIEF3a7n43dRN7Q=\"\n}\n}\n}\n]\n}\n\nThe issue you're experiencing with creating a Snowflake connection in AWS AppFlow could be due to several factors. Here are some potential areas to check and troubleshoot:\nNetwork Configuration: Ensure that your Snowflake account is accessible from AWS AppFlow. You mentioned using the network ID of your Snowflake account, but make sure it's correctly configured to allow incoming connections from AppFlow.\nSnowflake Storage Integration: Verify that your Snowflake storage integration is properly set up and linked to the correct S3 bucket. The storage integration should have the necessary permissions to access the S3 bucket.\nS3 Bucket Policy: Your S3 bucket policy looks correct for allowing AppFlow to perform the necessary actions. However, ensure that the bucket name in the Resource section matches exactly with the bucket you're using for the Snowflake integration.\nIAM Role: The IAM role policy you've provided seems to have the necessary permissions for S3 access. However, make sure this role is correctly associated with your AppFlow connection.\nTrust Relationship: The trust relationship you've shown is for an IAM user, not for the AppFlow service. For AppFlow to assume this role, you need to add the AppFlow service to the trust relationship.\nSnowflake Connection Parameters: Double-check that you've entered all the Snowflake connection parameters correctly in AppFlow, including the account name, warehouse, database, schema, and stage name.\nVPC and Security Groups: If you're using a VPC for your Snowflake connection, ensure that the security groups and network ACLs are configured to allow traffic between AppFlow and Snowflake.\nSnowflake User Permissions: Verify that the Snowflake user you're using for the connection has the necessary privileges to access the specified warehouse, database, and schema.\nIf you've verified all these points and are still encountering the timeout error, it might be worth reaching out to AWS support for more detailed troubleshooting, as they can inspect the specific configuration in your account.\nSources\nSnowflakeConnectorProfileProperties - AmazonAppFlow\nS3 connection to Snowflake | AWS re:Post\n\nAbove answer is correct. Additional references: Ensure that AppFlow's \"test connection\" functionality operates over the public internet rather than PrivateLink, [+] Verify these IP ranges in the AWS IP ranges documentation:\nhttps://docs.aws.amazon.com/vpc/latest/userguide/aws-ip-ranges.html\n\nAbove answer is correct.\nAdditional references:\nEnsure that AppFlow's \"test connection\" functionality operates over the public internet rather than PrivateLink,\n[+] Verify these IP ranges in the AWS IP ranges documentation:\nhttps://docs.aws.amazon.com/vpc/latest/userguide/aws-ip-ranges.html\n\nSince I am using the public connection. I have the Stage and storage integration on the snowflake side, which is mapped to the IAM role and S3 bucket set up. This basically adds the snowflake user arn and external id as the trusted connection for AWS. So does the IP ranges still needs to be verified on the snowflake side?\n\nThe issue is related to IPs of AWS APPFLOW that needs to be white-listed in snowflake. After adding the IPs the issue is resolved\nhttps://docs.aws.amazon.com/vpc/latest/userguide/aws-ip-ranges.html"
}