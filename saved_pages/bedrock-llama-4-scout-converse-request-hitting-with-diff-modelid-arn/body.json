{
  "body": "ARN loading from .env file is: arn:aws:bedrock:us-east-2:\n<Account-ID>\n:inference-profile/us.meta.llama4-scout-17b-instruct-v1:0\nbut getting error for diff ARN with diff zone & model-id\narn:aws:bedrock:us-east-1::foundation-model/meta.llama4-scout-17b-instruct-v1:0\n\nARN loded from .env is 'arn:aws:bedrock:us-east-1:\n<acc-id>\n:inference-profile/us.meta.llama4-scout-17b-instruct-v1:0'\nbut converse request is throwing error with a diff ARN:\narn:aws:bedrock:us-east-1::foundation-model/meta.llama4-scout-17b-instruct-v1:0\nError: An error occurred (AccessDeniedException) when calling the Converse operation: User: arn:aws:iam::\n<acc-id>\n:user/gen-ai-lab-user is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-scout-17b-instruct-v1:0 because no identity-based policy allows the bedrock:InvokeModel action\n\nSolution steps:\nadded permission entries the 3 supported regions in the \"model-inference-profile\" config page in AWS-console, as listed in the snippet below, the\nconverse\nAPI call started to working fine\n\"arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-maverick-17b-instruct-v1:0\",\n                \"arn:aws:bedrock:us-east-2::foundation-model/meta.llama4-maverick-17b-instruct-v1:0\",\n                \"arn:aws:bedrock:us-west-2::foundation-model/meta.llama4-maverick-17b-instruct-v1:0\",\n                \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-scout-17b-instruct-v1:0\",\n                \"arn:aws:bedrock:us-east-2::foundation-model/meta.llama4-scout-17b-instruct-v1:0\",\n                \"arn:aws:bedrock:us-west-2::foundation-model/meta.llama4-scout-17b-instruct-v1:0\",\n                \"arn:aws:bedrock:us-east-1:518282333572:inference-profile/us.meta.llama4-scout-17b-instruct-v1:0\",\n                \"arn:aws:bedrock:us-east-2:518282333572:inference-profile/us.meta.llama4-scout-17b-instruct-v1:0\",\n                \"arn:aws:bedrock:us-west-2:518282333572:inference-profile/us.meta.llama4-scout-17b-instruct-v1:0\",\n                \"arn:aws:bedrock:us-east-1:518282333572:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0\",\n                \"arn:aws:bedrock:us-east-2:518282333572:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0\",\n                \"arn:aws:bedrock:us-west-2:518282333572:inference-profile/us.meta.llama4-maverick-17b-instruct-v1:0\",\ncalled converse API with model-profile-arn:\narn:aws:bedrock:us-east-1:<aws-account-id>:inference-profile/us.meta.llama4-scout-17b-instruct-v1:0\n(as shown in aws-console model-permissions config page)\nThe earlier errors that were occurring on converse call, did not occur after making the above entries:\n\"AccessDeniedException\"\n\"(ValidationException) when calling the Converse operation: Invocation of model ID meta.llama4-scout-17b-instruct-v1:0 with on-demand throughput isn\u2019t supported.\""
}